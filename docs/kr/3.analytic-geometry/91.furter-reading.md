---
layout: default
title: 더 읽을거리
lang: kr
lang-ref: futher-reading
parent: 해석기하학
permalink: /kr/analytic-geometry/3-10
nav_order: 10
writer: bluvory
---

# 더 읽을거리
{: .no_toc }


Chapter 10 : Futher Reading
{: .fs-5 .fw-300 }


{% include writer.html writer=page.writer lang=page.lang %}

---

- 목차
    {: .text-gamma }

    1. TOC
    {:toc}

---

## 더 읽을거리

내부곱을 사용하면 각 벡터가 Gram-Schmidt 방법을 사용하여 다른 모든 벡터(직교 기저)와 직교하는 벡터(하위) 공간의 특정 기저를 결정할 수 있다.

이러한 기초는 선형 방정식 시스템 해결을 위한 최적화 및 수치 알고리즘에서 중요하다.

예를 들어, Krylov 부분 공간 방법(예: 결합 기울기 또는 일반화 최소 잔차 방법(GMRES)은 서로 직교하는 잔차 오류를 최소화합니다.

기계 학습에서 inner product은 kernel method의 맥락에서 중요하다.

kernel method은 많은 선형 알고리즘이 순수하게 inner product 계산으로 표현될 수 있다는 사실을 활용한다.

그런 다음 "kernel trick을 사용하면 이러한 내부 제품을 명시적으로 알지도 못한 채 (잠재적으로 무한 차원) feature 공간에서 암묵적으로 계산할 수 있다.

이를 통해 커널-PCA와 같은 기계 학습에 사용되는 많은 알고리즘의 "비선형화"가 가능해졌다.

가우스 프로세스도 kernel method의 범주에 속하며 확률적 회귀 분석(데이터 포인트에 원곡선을 적합)의 최신 기술이다.

커널에 대한 개념은 12장에서 자세히 설명한다.

projection은 그림자를 생성하기 위해 컴퓨터 그래픽에 자주 사용된다.

최적화에서 orthogonal projection은 잔차 오차를 최소화하기 위해 (반복적으로) 종종 사용된다.

이는 기계 학습에도 적용되며, 예를 들어, 데이터의 선형 함수에 대한 직교 투영 길이와 같이 잔차 오차를 최소화하는 (선형) 함수를 찾으려고 하는 경우에도 적용됩니다.

이에 대해서는 9장에서 자세히 알아보겠습니다.

PCA도 고차원 데이터의 치수 감소를 위해 투영법을 사용합니다.

이에 대한 자세한 내용은 10장에서 다루겠습니다.



---

{% include category.html category=page.parent id=10 %}
